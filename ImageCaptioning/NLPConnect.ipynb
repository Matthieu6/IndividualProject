{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLJlLBW/7DVN5HUBrZCOc2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthieu6/IndividualProject/blob/main/ImageCaptioning/NLPConnect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise"
      ],
      "metadata": {
        "id": "ljrQ_7Djpgi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section installs the required extensions to run NLPConnect. Additionally it initiates the pipelines required for the model."
      ],
      "metadata": {
        "id": "Ap92SCvNpuXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "max_length = 16\n",
        "num_beams = 4\n",
        "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n"
      ],
      "metadata": {
        "id": "j-FipvU2ttAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_step(image_paths):\n",
        "  images = []\n",
        "  for image_path in image_paths:\n",
        "    i_image = Image.open(image_path)\n",
        "    if i_image.mode != \"RGB\":\n",
        "      i_image = i_image.convert(mode=\"RGB\")\n",
        "\n",
        "    images.append(i_image)\n",
        "\n",
        "  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
        "  pixel_values = pixel_values.to(device)\n",
        "\n",
        "  output_ids = model.generate(pixel_values, **gen_kwargs)\n",
        "\n",
        "  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "  preds = [pred.strip() for pred in preds]\n",
        "  return preds\n"
      ],
      "metadata": {
        "id": "n4-76-OCRGDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "lubse48gplE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code used to generate captions from input images found on Flickr8K database."
      ],
      "metadata": {
        "id": "P1K6rrK3p-W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_1.jpg'])"
      ],
      "metadata": {
        "id": "Vcn7B9NCRdNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_2.jpg'])"
      ],
      "metadata": {
        "id": "1jpuzlhPRz-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_3.jpg'])"
      ],
      "metadata": {
        "id": "4USJKSEySD2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_4.jpg'])"
      ],
      "metadata": {
        "id": "iqD4Wi_kSDuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_5.jpg'])"
      ],
      "metadata": {
        "id": "UwD87mVjSDl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_6.jpg'])"
      ],
      "metadata": {
        "id": "HtxC3mejSDdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_7.jpg'])"
      ],
      "metadata": {
        "id": "3jiQohHsSDTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_8.jpg'])"
      ],
      "metadata": {
        "id": "e2LbriaRSDLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_9.jpg'])"
      ],
      "metadata": {
        "id": "l2ZPJRKFSDC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_10.jpg'])"
      ],
      "metadata": {
        "id": "sdWOViZMSCx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_11.jpg'])"
      ],
      "metadata": {
        "id": "i1wTT_L6SCPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_12.jpg'])"
      ],
      "metadata": {
        "id": "Fo0raSKjSLUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_13.jpg'])"
      ],
      "metadata": {
        "id": "CW41BfiQSLJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_step(['output_image_14.jpg'])"
      ],
      "metadata": {
        "id": "LldwNSLeSK-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}