{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNeY0t58QT2lSK9+plfG9aC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthieu6/IndividualProject/blob/main/ImageCaptioning/BLIP_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialise"
      ],
      "metadata": {
        "id": "fMWNTGnR2pan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section installs the required extensions to run BLIP-2. Additionally it initiates the pipelines required for the model. Modifications were done from the original file accessible on [HuggingFace](https://huggingface.co/Salesforce/blip2-opt-2.7b). "
      ],
      "metadata": {
        "id": "fbRW1VQiresx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install salesforce-lavis\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import requests\n",
        "from lavis.models import load_model_and_preprocess\n",
        "\n",
        "# setup device to use\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model, vis_processors, _ = load_model_and_preprocess(name=\"blip2_t5\", model_type=\"pretrain_flant5xxl\", is_eval=True, device=device)\n",
        "\n",
        "vis_processors.keys()\n"
      ],
      "metadata": {
        "id": "_kmZN_qXGghr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "iaqIi_ok2iwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code used to generate captions from input images found on Flickr8K database.\n",
        "\n",
        "During further testing, min_length and max_length was changed in order to obtain captions of different lengths."
      ],
      "metadata": {
        "id": "Nnl4Zo6QrlN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_1.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "X18wIbHDaK--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_2.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "wYbisCRGaTvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_3.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "e58R5jXPsPOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_4.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "tJyj8ELlaTbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_5.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "ldaesydNaTPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_6.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "SKlVod7RaTBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_7.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "tCnKJRETaS3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_8.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "yzKSxSKuaSsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_9.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "z9ZfbVe9aSiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_10.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "NGJO_8EhaSYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_11.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "Z-fxnBvlaSOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_12.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "w4NQq9RGaSE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_13.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "Ac0D-a5kaR7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_image = Image.open(\"output_image_14.jpg\").convert('RGB')\n",
        "\n",
        "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
        "model.generate({\"image\": image}, min_length = 16, max_length=64)\n"
      ],
      "metadata": {
        "id": "h9NAZnLMaRwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
