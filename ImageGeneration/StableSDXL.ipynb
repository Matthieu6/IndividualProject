{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "i12HuyCYUOm6"
      ],
      "authorship_tag": "ABX9TyP42l+OLIWd+MRFE+dF2knM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthieu6/IndividualProject/blob/main/ImageGeneration/StableSDXL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiation"
      ],
      "metadata": {
        "id": "i12HuyCYUOm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section installs the required extensions to run StableSDXL. Additionally it initiates the pipelines required for the model."
      ],
      "metadata": {
        "id": "5MvkNK7rol1w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTlut4etQbQW"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo = \"ByteDance/SDXL-Lightning\"\n",
        "ckpt = \"sdxl_lightning_8step_unet.safetensors\" # Use the correct ckpt for your step setting!\n",
        "\n",
        "# Load model.\n",
        "unet = UNet2DConditionModel.from_config(base, subfolder=\"unet\").to(\"cuda\", torch.float16)\n",
        "unet.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=\"cuda\"))\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(base, unet=unet, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "\n",
        "# Ensure sampler uses \"trailing\" timesteps.\n",
        "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n"
      ],
      "metadata": {
        "id": "8SxanAwKULvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code outputing 14 images using StableSDXL. Each image is generated from input captions created from the BLIP-2 image captioning model.\n"
      ],
      "metadata": {
        "id": "0SgZwzg6pH7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a woman paddling a canoe in a body of water\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image1.png\")"
      ],
      "metadata": {
        "id": "TWyJO8EFULUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a group of people skiing down a snowy hill on skis\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image2.png\")"
      ],
      "metadata": {
        "id": "BhKa10LNUi3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a man is paddling a canoe down a river\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image3.png\")"
      ],
      "metadata": {
        "id": "D2ZHU-QsUmyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a group of people sitting on a cliff overlooking a river\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image4.png\")"
      ],
      "metadata": {
        "id": "S9pgwbINUmn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a man and a woman sitting on the back of a car\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image5.png\")"
      ],
      "metadata": {
        "id": "sQOPQ3SLUmds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a man on a motorcycle is leaning around a corner\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image6.png\")"
      ],
      "metadata": {
        "id": "hDo9xgMAUmTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a person climbing up a rocky cliff on a rope\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image7.png\")"
      ],
      "metadata": {
        "id": "35zvZmgWUl8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a little girl sitting in the grass with a rainbow in front of her\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image8.png\")"
      ],
      "metadata": {
        "id": "ZMOZTWaWUlzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a dog running in the grass with a hose in front of it\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image9.png\")"
      ],
      "metadata": {
        "id": "xOcxZc9IUlpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a group of people riding a four wheeler in a field\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image10.png\")"
      ],
      "metadata": {
        "id": "XCJm29puUles"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"two small dogs walking on a stone path in the woods with bushes in the background\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image11.png\")"
      ],
      "metadata": {
        "id": "hayaxncMUlVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a woman is sitting on a green bench with a cup of coffee\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image12.png\")"
      ],
      "metadata": {
        "id": "J3Z8pPaLUlL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a man standing on top of a rock overlooking a valley\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image13.png\")"
      ],
      "metadata": {
        "id": "AyZU-pkJUlBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"a man in a green and yellow uniform with a towel on his head\", num_inference_steps=8, guidance_scale=0).images[0].save(\"output_image14.png\")"
      ],
      "metadata": {
        "id": "VynZktl2Ukr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}